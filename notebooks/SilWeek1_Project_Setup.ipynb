{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe7b563d-6a75-4d92-9412-c3fb1ae65197",
   "metadata": {},
   "source": [
    "#House Price Prediction Project: Environment Setup\n",
    "\n",
    "This notebook documents the setup process and planning for a O.A machine learning project to predict house prices. \n",
    "Project Goal: Build a regression model to predict house prices based on various features using the Kaggle Advanced Housing Price dataset.\n",
    "\n",
    "Date: [February 2025]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d29f510-bb98-4735-8521-55ac36ea346d",
   "metadata": {},
   "source": [
    "Project Overview\n",
    "\n",
    "Problem Statement\n",
    "House prices are influenced by numerous factors including location, size, amenities, and market conditions. Manual estimation is complex and often inaccurate. Machine learning offers a solution by analyzing patterns in historical data to make accurate predictions.\n",
    "\n",
    "Approach\n",
    "This project will use supervised learning regression techniques to predict house prices. Based on the Week 1 lecture by Ainish, this falls under the supervised learning category since we have labeled data (known house prices) to train our model.\n",
    "\n",
    "Dataset\n",
    "The project will use Kaggle's Advanced Housing Price Dataset, which includes:\n",
    "  Numeric features: square footage, number of rooms, year built, etc.\n",
    "  Categorical features: neighborhood, house style, condition, etc.\n",
    "  Target variable: Sale Price of houses\n",
    "\n",
    "Evaluation Metrics\n",
    "As discussed in the lecture, we'll evaluate our regression model using:\n",
    "- RMSE (Root Mean Squared Error)\n",
    "- MAE (Mean Absolute Error)\n",
    "- R² (R-squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a25b09-f64b-4447-96e6-d3f36e1dfec7",
   "metadata": {},
   "source": [
    "Based on Week 1 lecture materials, this project applies several key concepts:\n",
    "\n",
    " Artificial Intelligence & Machine Learning\n",
    "This project uses machine learning, a subset of AI, to create a system that learns from housing data to make price predictions without being explicitly programmed with real estate valuation rules.\n",
    "\n",
    " Types of Machine Learning Used\n",
    "   Supervised Learning: We're using labeled data (houses with known prices) to train a model that can predict prices for new houses.\n",
    "   Regression: Since we're predicting a continuous value (house price) rather than categories, this is specifically a regression problem.\n",
    "\n",
    " Statistical Concepts\n",
    "The project will apply statistical concepts such as:\n",
    "- Correlation analysis between features and house prices\n",
    "- Distribution analysis of numeric features\n",
    "- Hypothesis testing to identify significant predictors\n",
    "\n",
    " Data Science Workflow\n",
    "We'll follow the data science workflow outlined in the lecture:\n",
    "1. Data collection and cleaning\n",
    "2. Exploratory data analysis\n",
    "3. Feature engineering\n",
    "4. Model selection and training\n",
    "5. Evaluation and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16638eb-0456-4b82-b428-8a5dbc62e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python version and installed packages\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# List installed packages\n",
    "import pkg_resources\n",
    "installed_packages = pkg_resources.working_set\n",
    "installed_packages_list = sorted([f\"{i.key}=={i.version}\" for i in installed_packages])\n",
    "print(\"\\nInstalled packages:\")\n",
    "for package in installed_packages_list[:10]:  # Show first 10 packages\n",
    "    print(f\"  {package}\")\n",
    "print(\"  ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcccdb2-e398-4a7b-b432-c16954ff0596",
   "metadata": {},
   "source": [
    " Environment Setup\n",
    "\n",
    " Python and Virtual Environment\n",
    "For this project, I'm using:\n",
    "- Python 3.13.2 as the programming language\n",
    "- Pipenv for virtual environment and package management\n",
    "\n",
    "As discussed in the lecture, virtual environments allow:\n",
    "- Isolation of project dependencies\n",
    "- Consistent environments across different machines\n",
    "- Prevention of package conflicts between projects\n",
    "- Easy sharing of project requirements\n",
    "\n",
    " Setup Process\n",
    "1. Installed Pipenv: `pip install pipenv`\n",
    "2. Created a new environment: `pipenv install`\n",
    "3. Installed data science packages: `pipenv install numpy pandas matplotlib seaborn scikit-learn jupyter`\n",
    "4. Activated the environment: `pipenv shell`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200f0753-b7ed-4be3-9dd7-5945b6e61dda",
   "metadata": {},
   "source": [
    " Version Control with Git\n",
    "Based on the lecture, version control is essential for tracking changes and collaborating on projects.\n",
    " Git Setup\n",
    "1. Initialized Git repository: `git init`\n",
    "2. Created .gitignore file to exclude:\n",
    "   - Virtual environment files (`/.venv/`)\n",
    "   - Large datasets (`/data/*.csv`)\n",
    "   - Jupyter checkpoints (`/.ipynb_checkpoints/`)\n",
    "   - Cached Python files (`__pycache__/`, `*.pyc`)\n",
    "\n",
    " GitHub Integration (Future)\n",
    "In the next session, I'll connect this local repository to GitHub for:\n",
    "- Remote backup\n",
    "- Version history tracking\n",
    "- Potential collaboration\n",
    "- Project portfolio showcasing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07e928d-5e0c-462f-9660-bf4e9678e120",
   "metadata": {},
   "source": [
    " AWS Cloud Computing \n",
    "\n",
    "The lecture highlighted the importance of cloud computing for scalable data science projects.\n",
    " Planned AWS Services\n",
    "1. S3 (Simple Storage Service)\n",
    "   - Store large datasets\n",
    "   - Share results and visualizations\n",
    "\n",
    "2. EC2 (Elastic Compute Cloud)\n",
    "   - Run computationally intensive models\n",
    "   - Scale resources as needed\n",
    "\n",
    "3. SageMaker (Potential)\n",
    "   - Build, train, and deploy ML models\n",
    "   - Access pre-built algorithms\n",
    "\n",
    " Implementation Timeline\n",
    "AWS integration will be implemented in later stages of the project when we need additional computational resources or deployment options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e16cc-a083-409a-9265-8b1e8392c27d",
   "metadata": {},
   "source": [
    " Project Structure\n",
    "\n",
    "I've organized the project with the following structure:\n",
    "HousePricePrediction/\n",
    "├── data/ # Dataset files\n",
    "├── notebooks/ # Jupyter notebooks (including this file)\n",
    "├── docs/ # Documentation\n",
    "├── Pipfile # Pipenv package requirements\n",
    "├── Pipfile.lock # Locked dependencies\n",
    "└── README.md # Project overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f3d2ce-3a61-4bfe-adbb-7ed4654310f8",
   "metadata": {},
   "source": [
    " Reflections and Learnings\n",
    "\n",
    " Key Takeaways from Week 1\n",
    "- I've learned that AI is the broader field of creating intelligent machines, ML is a subset focused on learning from data, statistics provides the mathematical foundation, and data science combines all these with domain expertise to extract insights.\n",
    "- I now understand the distinctions between supervised learning (using labeled data to predict outcomes), unsupervised learning (finding patterns in unlabeled data), reinforcement learning (learning through trial and error), and semi-supervised learning (combining labeled and unlabeled data).\n",
    "- I've gained experience setting up Python, pipenv for virtual environment management, and Jupyter Notebook as my IDE for this project.\n",
    "- I've learned the importance of proper project organization, documentation, and planning before diving into implementation.\n",
    "\n",
    " Challenges Encountered\n",
    "- I faced difficulties with the Python command not being recognized in the command prompt despite installation. This was due to PATH environment variable issues in Windows.\n",
    "- Initially, I found it challenging to grasp how pipenv manages dependencies and creates isolated environments.\n",
    "- I encountered some confusion about how to start, stop, and create new notebooks in the Jupyter environment.\n",
    "\n",
    " How I Overcame These Challenges\n",
    "- For Python PATH issues, I reinstalled Python with the \"Add to PATH\" option checked and verified the installation using alternative commands like `py --version`.\n",
    "- I researched virtual environments through documentation and tutorials to better understand how pipenv isolates project dependencies.\n",
    "- I learned Jupyter Notebook commands through trial and error, discovering how to use keyboard shortcuts to efficiently manage the notebook environment.\n",
    "\n",
    " Questions for Further Exploration\n",
    "- How do different regression algorithms compare in performance for house price prediction tasks?\n",
    "- What techniques are most effective for handling categorical variables in housing datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae99dd0a-06af-4372-a5e3-39e8d5cea520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the data directory:\n",
      "['data_description.txt', 'sample_submission.csv', 'test.csv', 'train.csv']\n",
      "\n",
      "Training dataset loaded successfully with 1460 rows and 81 columns\n",
      "\n",
      "First 5 rows of the training dataset:\n",
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
      "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
      "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
      "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
      "\n",
      "  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0   2008        WD         Normal     208500  \n",
      "1   2007        WD         Normal     181500  \n",
      "2   2008        WD         Normal     223500  \n",
      "3   2006        WD        Abnorml     140000  \n",
      "4   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List files in data directory\n",
    "print(\"Files in the data directory:\")\n",
    "data_files = os.listdir('../data')\n",
    "print(data_files)\n",
    "\n",
    "# Load the training dataset\n",
    "train_data_path = '../data/train.csv'\n",
    "if os.path.exists(train_data_path):\n",
    "    train_df = pd.read_csv(train_data_path)\n",
    "    print(f\"\\nTraining dataset loaded successfully with {train_df.shape[0]} rows and {train_df.shape[1]} columns\")\n",
    "\n",
    "    # Display the first few rows\n",
    "    print(\"\\nFirst 5 rows of the training dataset:\")\n",
    "    print(train_df.head())\n",
    "else:\n",
    "    print(f\"\\nError: Could not find {train_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb2cd1-536c-4416-9ba0-6bd79b63f15f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
